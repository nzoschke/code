#!/usr/bin/env python

import argparse
import base64
import hmac, sha
import inspect
import os
import shutil
from string import Template
import subprocess
import sys
import tempfile
from time import time
import urllib
from urlparse import urlparse

def log(*data):
  # log() is a decorator if first argument is a function, otherwise a printer
  data = list(data)
  if hasattr(data[0], "__call__"):
    fn = data.pop(0)
    log_ctx = []

    def inner(*args, **kw):
      # The decorator keeps a context of log data. If the function accepts a 
      # log_ctx argument, it can mutate this context.
      if "log_ctx" in inspect.getargspec(fn).args:
        kw["log_ctx"] = log_ctx

      try:
        start = time()
        log(("file", __file__), ("fn", fn.__name__), ("at", "start"))
        result = fn(*args, **kw)
        log(("file", __file__), ("fn", fn.__name__), ("at", "finish"), ("elapsed", time()-start), *log_ctx)
        return result
      except Exception, e:
        exc = sys.exc_info()
        log(
          ("file", __file__), ("fn", fn.__name__), ("at", "error"), 
          ("class", "%s.%s" % (exc[0].__module__, exc[0].__name__)), ("message", exc[1]), ("elapsed", time()-start),
          *log_ctx
        )
        raise exc[0], exc[1], exc[2]
    return inner

  # print data
  kvs = []
  for d in data:
    if isinstance(d, basestring):
      kvs.append(d)
    else:
      kvs.append("%s=%s" % d) # presumably tuple or list
  sys.stderr.write(" ".join(kvs) + "\n")

class S3(object):
  def __init__(self, method, src=None, dest=None, url=False, ttl=30):
    self.method = method
    self.src    = src
    self.dest   = dest
    self.ttl    = ttl

    if os.path.isdir(self.dest) or self.dest.endswith("/"):
      self.dest = os.path.join(self.dest, os.path.basename(self.src))

    m = self.method
    if url:
      m += "_url"
    self.__getattribute__(m)()

  def signed_url(self, method, url):
    try:
      AWSAccessKeyId      = os.environ["S3_ACCESS_KEY_ID"]
      AWSSecretAccessKey  = os.environ["S3_SECRET_ACCESS_KEY"]
    except KeyError, e:
      print "error: S3_ACCESS_KEY_ID and S3_SECRET_ACCESS_KEY not set"
      sys.exit(1)

    uri     = urlparse(url)
    bucket  = uri.hostname
    key     = uri.path[1:]
    expires = int(time()) + self.ttl

    canonical_string = "/%s/%s" % (bucket, key)
    stringToSign = method + "\n\n\n" + str(expires) + "\n" + canonical_string
    signature = base64.b64encode(hmac.new(AWSSecretAccessKey, stringToSign, sha).digest())
    return "http://"+bucket+".s3.amazonaws.com/"+urllib.quote(key)+"?AWSAccessKeyId="+urllib.quote(AWSAccessKeyId)+"&Expires="+str(expires)+"&Signature="+urllib.quote(signature)

  @log
  def get(self, log_ctx):
    conf = """
      output  = "$output"
      request = "GET"
      url     = "$url"
    """

    conf = Template(conf).substitute(
      output=self.dest,
      url=self.signed_url("GET", self.src)
    )
    return self.curl(conf, log_ctx)

  @log
  def put(self, log_ctx):
    conf = """
      request     = "PUT"
      upload-file = "$upload_file"
      url         = "$url"
    """
    conf = Template(conf).substitute(
      upload_file=self.src,
      url=self.signed_url("PUT", self.dest)
    )
    return self.curl(conf, log_ctx)

  def curl(self, conf, log_ctx):
    conf += """
      connect-timeout = 5
      dump-header     = "$dump_header"
      max-time        = 60
      retry           = 1
      silent          = "true"
      speed-time      = 30
      speed-limit     = 3000
      write-out       = "code=%{http_code} size=%{size_download} speed=%{speed_download} time=%{time_total}"
    """

    with tempfile.NamedTemporaryFile() as header_file:
      conf = Template(conf).substitute(dump_header=header_file.name)
      p = subprocess.Popen(["curl", "--config", "-"], stdin=subprocess.PIPE, stdout=subprocess.PIPE, stderr=subprocess.PIPE)
      stdout, stderr = p.communicate(input=conf)

      headers = {}
      for line in header_file.readlines():
        l = line.split(":", 1)
        if len(l) == 2:
          headers[l[0]] = l[1].strip()

    log_ctx += [
      ("x-amz-id-2",        headers["x-amz-id-2"]),
      ("x-amz-request-id",  headers["x-amz-request-id"]),
      stdout
    ]

    return True

  def get_url(self):
    print self.signed_url("GET", self.src)

  def put_url(self):
    print self.signed_url("PUT", self.dest)

if __name__ == "__main__":
  parser      = argparse.ArgumentParser(
    description="Generate signed S3 URLs, and GET/PUT S3 objects via cURL",
    epilog="""
      S3_ACCESS_KEY_ID and S3_SECRET_ACCESS_KEY must be passed via the environment.
      S3_SRC or S3_DEST can be passed instead of --src or --dest.
    """
  )
  subparsers  = parser.add_subparsers()
  parser_get  = subparsers.add_parser("get")
  parser_put  = subparsers.add_parser("put")

  parser_get.add_argument("--src",  help="source URL to GET object", required=True)
  parser_get.add_argument("--dest", help="destination path to write object (default .)", default=".")
  parser_get.add_argument("--url",  help="generate signed URL instead of performing GET", action="store_true")
  parser_get.add_argument("--ttl",  help="signed URL time to live in seconds (default 30)", type=int, default=30)
  parser_get.set_defaults(method="get")

  parser_put.add_argument("--src",  help="source path to read object")
  parser_put.add_argument("--dest", help="destination URL to PUT object", required=True)
  parser_put.add_argument("--url",  help="generate signed URL instead of performing PUT", action="store_true")
  parser_put.add_argument("--ttl",  help="signed URL time to live in seconds (default 30)", type=int, default=30)
  parser_put.set_defaults(method="put")

  # read S3_DEST, S3_SRC args from env
  argv = sys.argv[1:]
  for f in ["dest", "src"]:
    k = "S3_%s" % f.replace("-", "_").upper()
    if os.environ.get(k):
      argv += ["--%s" % f, os.environ[k]]

  args = parser.parse_args(argv)
  s3 = S3(**vars(args))
